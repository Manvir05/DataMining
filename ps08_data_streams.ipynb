{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 08: Data streams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <font color=\"blue\">Manvir Kaur Singh</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">manvir.kaur01@estudiant.upf.edu</font>\n",
    "\n",
    "Date: <font color=\"blue\">3/12/2023</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import nltk\n",
    "import gzip\n",
    "import random\n",
    "import statistics\n",
    "import secrets\n",
    "import re\n",
    "import gzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset and how to iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "INPUT_FILE = \"movie_lines.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "# Producer in Python that reads a filename by words\n",
    "def read_by_words(filename, max_words=-1, report_every=-1):\n",
    "    \n",
    "    # Open the input file\n",
    "    with gzip.open(INPUT_FILE, \"rt\", encoding='utf8') as file:\n",
    "        \n",
    "        # Initialize counter of words to stop at max_words\n",
    "        counter = 0\n",
    "    \n",
    "        # Regular expression to identify words having 3 letters or more and beginning with a-z\n",
    "        word_expr = re.compile('^[a-z]{2,}$', re.IGNORECASE)\n",
    "\n",
    "        # Iterate through lines in the file\n",
    "        for line in file:\n",
    "            \n",
    "            elements = line.split(\"\\t\")\n",
    "            \n",
    "            text = \"\"\n",
    "            if len(elements) >= 5:\n",
    "                text = elements[4].strip()\n",
    "                                        \n",
    "            if counter > max_words and max_words != -1:\n",
    "                break\n",
    "                \n",
    "            for word in nltk.word_tokenize(text):\n",
    "                          \n",
    "                if word_expr.match(word):\n",
    "                    counter += 1\n",
    "                    \n",
    "                    # Report\n",
    "                    if (report_every != -1) and (counter % report_every == 0):\n",
    "                        if max_words == -1:\n",
    "                            print(\"- Read %d words so far\" % (counter))\n",
    "                        else:\n",
    "                            print(\"- Read %d/%d words so far\" % (counter, max_words))\n",
    "\n",
    "                    # Produce the word in lowercase\n",
    "                    yield word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current word 'her'\n",
      "Current word 'dangerous'\n",
      "Current word 'your'\n",
      "Current word 'the'\n",
      "Current word 'absolute'\n",
      "Current word 'kids'\n",
      "Current word 'that'\n",
      "Current word 'room'\n",
      "Current word 'for'\n",
      "Current word 'well'\n",
      "Current word 'thank'\n",
      "Current word 'it'\n",
      "Current word 'see'\n",
      "Current word 'closes'\n",
      "Current word 'been'\n",
      "- Read 100000/300000 words so far\n",
      "Current word 'you'\n",
      "Current word 'why'\n",
      "Current word 'where'\n",
      "Current word 'to'\n",
      "Current word 'in'\n",
      "Current word 'french'\n",
      "Current word 'it'\n",
      "Current word 'ring'\n",
      "- Read 200000/300000 words so far\n",
      "Current word 'charge'\n",
      "Current word 'together'\n",
      "Current word 'get'\n",
      "Current word 'me'\n",
      "Current word 'go'\n",
      "Current word 'phones'\n",
      "Current word 'would'\n",
      "Current word 'one'\n",
      "Current word 'stand'\n",
      "Current word 'right'\n",
      "Current word 'of'\n",
      "Current word 'the'\n",
      "Current word 'be'\n",
      "Current word 'everything'\n",
      "- Read 300000/300000 words so far\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "# Iterate through the file\n",
    "for word in read_by_words(INPUT_FILE, max_words=300000, report_every=100000):\n",
    "    # Prints 1/10000 of words\n",
    "    if random.random() < 0.0001:\n",
    "        print(\"Current word '%s'\" % (word)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if above gives an error about 'punkt'\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Determine approximately the top-10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Implement \"add_reservoir\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_reservoir(reservoir, item, max_reservoir_size):\n",
    "    if len(reservoir) < max_reservoir_size:\n",
    "        reservoir.append(item)\n",
    "    else:\n",
    "        random_index = random.randint(0, max_reservoir_size - 1)\n",
    "        reservoir[random_index] = item\n",
    "    assert(len(reservoir) <= max_reservoir_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Implement \"reservoir_sampling\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reservoir_sampling(filename, reservoir_size, max_words=-1, report_every=-1):\n",
    "    reservoir = []\n",
    "    \n",
    "    words_read = 0\n",
    "    \n",
    "    for word in read_by_words(filename, max_words=max_words, report_every=report_every):\n",
    "        words_read += 1\n",
    "        ptocheck = random.random()\n",
    "        if ptocheck > reservoir_size/words_read:\n",
    "            add_to_reservoir(reservoir, word, reservoir_size)\n",
    "\n",
    "    return (words_read, reservoir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read 100000/1000000 words so far\n",
      "- Read 200000/1000000 words so far\n",
      "- Read 300000/1000000 words so far\n",
      "- Read 400000/1000000 words so far\n",
      "- Read 500000/1000000 words so far\n",
      "- Read 600000/1000000 words so far\n",
      "- Read 700000/1000000 words so far\n",
      "- Read 800000/1000000 words so far\n",
      "- Read 900000/1000000 words so far\n",
      "- Read 1000000/1000000 words so far\n",
      "Number of items seen    : 1000028\n",
      "Number of items sampled : 1500\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "reservoir_size = 1500\n",
    "(items_seen, reservoir) = reservoir_sampling(INPUT_FILE, reservoir_size, max_words=1000000, report_every=100000)\n",
    "\n",
    "print(\"Number of items seen    : %d\" % items_seen)\n",
    "print(\"Number of items sampled : %d\" % len(reservoir) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 you\n",
      "49 it\n",
      "41 the\n",
      "40 to\n",
      "22 me\n",
      "22 and\n",
      "20 is\n",
      "20 do\n",
      "19 that\n",
      "17 what\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "freq = {}\n",
    "for item in reservoir:\n",
    "    freq[item] = reservoir.count(item)\n",
    "\n",
    "most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:10]\n",
    "for absolute_frequency, word in most_frequent_items:\n",
    "    print(\"%d %s\" % (absolute_frequency, word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Print the top items and their relative frequencies</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 you (4.40%)\n",
      "49 it (3.27%)\n",
      "41 the (2.73%)\n",
      "40 to (2.67%)\n",
      "22 me (1.47%)\n",
      "22 and (1.47%)\n",
      "20 is (1.33%)\n",
      "20 do (1.33%)\n",
      "19 that (1.27%)\n",
      "17 what (1.13%)\n",
      "15 your (1.00%)\n",
      "15 of (1.00%)\n",
      "15 in (1.00%)\n",
      "14 lenny (0.93%)\n",
      "14 her (0.93%)\n"
     ]
    }
   ],
   "source": [
    "freq = {}\n",
    "for item in reservoir:\n",
    "    freq[item] = reservoir.count(item)\n",
    "\n",
    "total_items = len(reservoir)\n",
    "most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:15]\n",
    "for absolute_frequency, word in most_frequent_items:\n",
    "    relative_frequency = (absolute_frequency / total_items) * 100\n",
    "    print(\"%d %s (%.2f%%)\" % (absolute_frequency, word, relative_frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Increase the max limit of words so that one pass takes no more than 5 minutes to be completed.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read 1000000/2000000 words so far\n",
      "- Read 2000000/2000000 words so far\n",
      "Word: you\n",
      "appeareances in reservoir: 3\n",
      "Absolute frequency (approx for entire dataset) 120001.320000\n",
      "Relative frequency (approx) 6.000000%\n",
      "Word: to\n",
      "appeareances in reservoir: 3\n",
      "Absolute frequency (approx for entire dataset) 120001.320000\n",
      "Relative frequency (approx) 6.000000%\n",
      "Word: that\n",
      "appeareances in reservoir: 3\n",
      "Absolute frequency (approx for entire dataset) 120001.320000\n",
      "Relative frequency (approx) 6.000000%\n",
      "Word: she\n",
      "appeareances in reservoir: 2\n",
      "Absolute frequency (approx for entire dataset) 80000.880000\n",
      "Relative frequency (approx) 4.000000%\n",
      "Word: know\n",
      "appeareances in reservoir: 2\n",
      "Absolute frequency (approx for entire dataset) 80000.880000\n",
      "Relative frequency (approx) 4.000000%\n",
      "- Read 1000000/2000000 words so far\n",
      "- Read 2000000/2000000 words so far\n",
      "Word: to\n",
      "appeareances in reservoir: 6\n",
      "Absolute frequency (approx for entire dataset) 120001.320000\n",
      "Relative frequency (approx) 6.000000%\n",
      "Word: the\n",
      "appeareances in reservoir: 6\n",
      "Absolute frequency (approx for entire dataset) 120001.320000\n",
      "Relative frequency (approx) 6.000000%\n",
      "Word: you\n",
      "appeareances in reservoir: 5\n",
      "Absolute frequency (approx for entire dataset) 100001.100000\n",
      "Relative frequency (approx) 5.000000%\n",
      "Word: that\n",
      "appeareances in reservoir: 3\n",
      "Absolute frequency (approx for entire dataset) 60000.660000\n",
      "Relative frequency (approx) 3.000000%\n",
      "Word: she\n",
      "appeareances in reservoir: 3\n",
      "Absolute frequency (approx for entire dataset) 60000.660000\n",
      "Relative frequency (approx) 3.000000%\n",
      "- Read 1000000/2000000 words so far\n",
      "- Read 2000000/2000000 words so far\n",
      "Word: you\n",
      "appeareances in reservoir: 20\n",
      "Absolute frequency (approx for entire dataset) 80000.880000\n",
      "Relative frequency (approx) 4.000000%\n",
      "Word: the\n",
      "appeareances in reservoir: 20\n",
      "Absolute frequency (approx for entire dataset) 80000.880000\n",
      "Relative frequency (approx) 4.000000%\n",
      "Word: to\n",
      "appeareances in reservoir: 17\n",
      "Absolute frequency (approx for entire dataset) 68000.748000\n",
      "Relative frequency (approx) 3.400000%\n",
      "Word: it\n",
      "appeareances in reservoir: 11\n",
      "Absolute frequency (approx for entire dataset) 44000.484000\n",
      "Relative frequency (approx) 2.200000%\n",
      "Word: that\n",
      "appeareances in reservoir: 10\n",
      "Absolute frequency (approx for entire dataset) 40000.440000\n",
      "Relative frequency (approx) 2.000000%\n",
      "- Read 1000000/2000000 words so far\n",
      "- Read 2000000/2000000 words so far\n",
      "Word: the\n",
      "appeareances in reservoir: 45\n",
      "Absolute frequency (approx for entire dataset) 90000.990000\n",
      "Relative frequency (approx) 4.500000%\n",
      "Word: to\n",
      "appeareances in reservoir: 35\n",
      "Absolute frequency (approx for entire dataset) 70000.770000\n",
      "Relative frequency (approx) 3.500000%\n",
      "Word: you\n",
      "appeareances in reservoir: 30\n",
      "Absolute frequency (approx for entire dataset) 60000.660000\n",
      "Relative frequency (approx) 3.000000%\n",
      "Word: it\n",
      "appeareances in reservoir: 29\n",
      "Absolute frequency (approx for entire dataset) 58000.638000\n",
      "Relative frequency (approx) 2.900000%\n",
      "Word: that\n",
      "appeareances in reservoir: 23\n",
      "Absolute frequency (approx for entire dataset) 46000.506000\n",
      "Relative frequency (approx) 2.300000%\n",
      "- Read 1000000/2000000 words so far\n",
      "- Read 2000000/2000000 words so far\n",
      "Word: you\n",
      "appeareances in reservoir: 86\n",
      "Absolute frequency (approx for entire dataset) 86000.946000\n",
      "Relative frequency (approx) 4.300000%\n",
      "Word: the\n",
      "appeareances in reservoir: 78\n",
      "Absolute frequency (approx for entire dataset) 78000.858000\n",
      "Relative frequency (approx) 3.900000%\n",
      "Word: to\n",
      "appeareances in reservoir: 65\n",
      "Absolute frequency (approx for entire dataset) 65000.715000\n",
      "Relative frequency (approx) 3.250000%\n",
      "Word: it\n",
      "appeareances in reservoir: 40\n",
      "Absolute frequency (approx for entire dataset) 40000.440000\n",
      "Relative frequency (approx) 2.000000%\n",
      "Word: me\n",
      "appeareances in reservoir: 34\n",
      "Absolute frequency (approx for entire dataset) 34000.374000\n",
      "Relative frequency (approx) 1.700000%\n",
      "- Read 1000000/2000000 words so far\n",
      "- Read 2000000/2000000 words so far\n",
      "Word: you\n",
      "appeareances in reservoir: 205\n",
      "Absolute frequency (approx for entire dataset) 102501.127500\n",
      "Relative frequency (approx) 5.125000%\n",
      "Word: the\n",
      "appeareances in reservoir: 165\n",
      "Absolute frequency (approx for entire dataset) 82500.907500\n",
      "Relative frequency (approx) 4.125000%\n",
      "Word: to\n",
      "appeareances in reservoir: 110\n",
      "Absolute frequency (approx for entire dataset) 55000.605000\n",
      "Relative frequency (approx) 2.750000%\n",
      "Word: it\n",
      "appeareances in reservoir: 86\n",
      "Absolute frequency (approx for entire dataset) 43000.473000\n",
      "Relative frequency (approx) 2.150000%\n",
      "Word: that\n",
      "appeareances in reservoir: 68\n",
      "Absolute frequency (approx for entire dataset) 34000.374000\n",
      "Relative frequency (approx) 1.700000%\n",
      "- Read 1000000/2000000 words so far\n",
      "- Read 2000000/2000000 words so far\n",
      "Word: you\n",
      "appeareances in reservoir: 279\n",
      "Absolute frequency (approx for entire dataset) 93001.023000\n",
      "Relative frequency (approx) 4.650000%\n",
      "Word: the\n",
      "appeareances in reservoir: 223\n",
      "Absolute frequency (approx for entire dataset) 74334.151000\n",
      "Relative frequency (approx) 3.716667%\n",
      "Word: to\n",
      "appeareances in reservoir: 188\n",
      "Absolute frequency (approx for entire dataset) 62667.356000\n",
      "Relative frequency (approx) 3.133333%\n",
      "Word: it\n",
      "appeareances in reservoir: 152\n",
      "Absolute frequency (approx for entire dataset) 50667.224000\n",
      "Relative frequency (approx) 2.533333%\n",
      "Word: do\n",
      "appeareances in reservoir: 94\n",
      "Absolute frequency (approx for entire dataset) 31333.678000\n",
      "Relative frequency (approx) 1.566667%\n",
      "- Read 1000000/2000000 words so far\n",
      "- Read 2000000/2000000 words so far\n",
      "Word: you\n",
      "appeareances in reservoir: 400\n",
      "Absolute frequency (approx for entire dataset) 100001.100000\n",
      "Relative frequency (approx) 5.000000%\n",
      "Word: the\n",
      "appeareances in reservoir: 274\n",
      "Absolute frequency (approx for entire dataset) 68500.753500\n",
      "Relative frequency (approx) 3.425000%\n",
      "Word: to\n",
      "appeareances in reservoir: 228\n",
      "Absolute frequency (approx for entire dataset) 57000.627000\n",
      "Relative frequency (approx) 2.850000%\n",
      "Word: it\n",
      "appeareances in reservoir: 187\n",
      "Absolute frequency (approx for entire dataset) 46750.514250\n",
      "Relative frequency (approx) 2.337500%\n",
      "Word: and\n",
      "appeareances in reservoir: 132\n",
      "Absolute frequency (approx for entire dataset) 33000.363000\n",
      "Relative frequency (approx) 1.650000%\n"
     ]
    }
   ],
   "source": [
    "reservoir_sizes = [50, 100, 500, 1000, 2000, 4000, 6000, 8000]\n",
    "\n",
    "for reservoir_size in reservoir_sizes:\n",
    "    (items_seen, le_reservoir) = reservoir_sampling(INPUT_FILE, reservoir_size, max_words=2000000, report_every=1000000)\n",
    "\n",
    "    freq = {}\n",
    "    for item in le_reservoir:\n",
    "        freq[item] = le_reservoir.count(item)\n",
    "\n",
    "    most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:5]\n",
    "    for reservoir_freq, word in most_frequent_items:\n",
    "        print('Word:', word)\n",
    "        print('appeareances in reservoir:', reservoir_freq)\n",
    "        absolute_frequency = reservoir_freq*(items_seen/reservoir_size)\n",
    "        print('Absolute frequency (approx for entire dataset) %f' % absolute_frequency)\n",
    "        print('Relative frequency (approx) %f%%' % ((absolute_frequency/(items_seen))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Find by trial and error, and include in your report, the minimum reservoir size you need to have somewhat stable results</font>\n",
    "\n",
    "After running tests, it seems that for sizes bigger than 500 the top words remain stable. Then we can suggests that a reservoir size of 500 is sufficient for stability. Stability in this context means that the top words selected by the reservoir sampling algorithm are consistent across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read 1000000 words so far\n",
      "- Read 2000000 words so far\n",
      "Word: to\n",
      "appeareances in reservoir: 3\n",
      "Absolute frequency (approx for entire dataset) 176693.040000\n",
      "Relative frequency (approx) 6.000000%\n",
      "Word: your\n",
      "appeareances in reservoir: 2\n",
      "Absolute frequency (approx for entire dataset) 117795.360000\n",
      "Relative frequency (approx) 4.000000%\n",
      "Word: you\n",
      "appeareances in reservoir: 2\n",
      "Absolute frequency (approx for entire dataset) 117795.360000\n",
      "Relative frequency (approx) 4.000000%\n",
      "Word: with\n",
      "appeareances in reservoir: 2\n",
      "Absolute frequency (approx for entire dataset) 117795.360000\n",
      "Relative frequency (approx) 4.000000%\n",
      "Word: vereker\n",
      "appeareances in reservoir: 2\n",
      "Absolute frequency (approx for entire dataset) 117795.360000\n",
      "Relative frequency (approx) 4.000000%\n",
      "- Read 1000000 words so far\n",
      "- Read 2000000 words so far\n"
     ]
    }
   ],
   "source": [
    "# Perform reservoir sampling without a max_words limit\n",
    "reservoir_sizes = [50, 100, 500, 1000, 2000, 4000, 6000, 8000]\n",
    "\n",
    "for reservoir_size in reservoir_sizes:\n",
    "    (items_seen, le_reservoir) = reservoir_sampling(INPUT_FILE, reservoir_size, report_every=1000000)\n",
    "\n",
    "    freq = {}\n",
    "    for item in le_reservoir:\n",
    "        freq[item] = le_reservoir.count(item)\n",
    "\n",
    "    most_frequent_items = sorted([(frequency, word) for word, frequency in freq.items()], reverse=True)[:5]\n",
    "    for reservoir_freq, word in most_frequent_items:\n",
    "        print('Word:', word)\n",
    "        print('appeareances in reservoir:', reservoir_freq)\n",
    "        absolute_frequency = reservoir_freq*(items_seen/reservoir_size)\n",
    "        print('Absolute frequency (approx for entire dataset) %f' % absolute_frequency)\n",
    "        print('Relative frequency (approx) %f%%' % ((absolute_frequency/(items_seen))*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Brief commentary indicating what reservoir size you would recommend to use, and your overall conclusions.</font>\n",
    "\n",
    "For a relatively stable set of top words, a reservoir size of 500 seems to be adequate as before.\n",
    "As reservoir size is increased, the top words remained consistent across runs, indicating that a larger reservoir captures more representative samples from the dataset. The top words, along with their absolute and relative frequencies, show consistency in multiple runs, especially for reservoir sizes larger than 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Determine approximately the distinct number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def count_trailing_zeroes(number):\n",
    "    count = 0\n",
    "    while number & 1 == 0:\n",
    "        count += 1\n",
    "        number = number >> 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def random_hash_function():\n",
    "    # We use a cryptographically safe generator for the salt of our hash function\n",
    "    salt = secrets.token_bytes(32)\n",
    "    return lambda string: hash(string + str(salt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Perform the requested number of passes.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_word_estimates(number_of_passes):\n",
    "    estimates = []\n",
    "\n",
    "    for i in range(number_of_passes):\n",
    "        \n",
    "        hash_function = random_hash_function()\n",
    "        \n",
    "        maxR = 0\n",
    "\n",
    "        for word in read_by_words(INPUT_FILE, report_every=2000000):\n",
    "            r = count_trailing_zeroes(hash_function(word))\n",
    "            maxR = max(r, maxR)\n",
    "            \n",
    "        estimate = 2**maxR\n",
    "\n",
    "        estimates.append(estimate)\n",
    "        print(\"Estimate on pass %d: %d distinct words\" % (i+1, estimate))\n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = distinct_word_estimates(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "print(\"* Average of estimates: %.1f\" % statistics.mean(estimates))\n",
    "print(\"* Median  of estimates: %.1f\" % statistics.median(estimates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Remove the limit of max words, or set to a high number. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---> Runs for 10 passes')\n",
    "for i in range(3):\n",
    "    print('run #%d' % (i + 1))\n",
    "    estimates10 = distinct_word_estimates(10)\n",
    "    print(\"* Average of estimates: %.1f\" % statistics.mean(estimates10))\n",
    "    print(\"* Median  of estimates: %.1f\" % statistics.median(estimates10))\n",
    "\n",
    "print('---> Runs for 20 passes')\n",
    "for i in range(3):\n",
    "    print('run #%d' % (i + 1))\n",
    "    estimates20 = distinct_word_estimates(20)\n",
    "    print(\"* Average of estimates: %.1f\" % statistics.mean(estimates20))\n",
    "    print(\"* Median  of estimates: %.1f\" % statistics.median(estimates20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big averages happen because really big or small numbers affect them a lot. A median, which is just the middle number, is better here because it doesn't get messed up by those really big or small numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
